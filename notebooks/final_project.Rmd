---
title: "Final Project"
output: html_notebook
author: "Sai Krishna"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE) 
```

```{r include = FALSE}
setwd("C:/Users/saikr/Desktop/Q4/Time Series/Final Project")
```

```{r}
library(forecast)
library(tseries)
library(ggplot2)
```


```{r}
weather_data <- read.csv("final_data_1970_2023.csv")
```

```{r}
# Convert datetime column to POSIXct if needed
weather_data$datetime <- as.POSIXct(weather_data$datetime)
range(weather_data$datetime)
```
```{r}
#Calculate the average daily temparature
weather_data$avg_temp = (weather_data$tempmax + weather_data$tempmin)/2
```


```{r}
df.ts <- ts(weather_data, start = c(1970,1), frequency = 365.25)
df.ts_1 <- ts(weather_data, start = c(1970,121.25), frequency = 365.25)
```


```{r}
plot(df.ts[,'avg_temp'], main = "Daily Average Temparature")
plot(df.ts[,'tempmax'], main = "Daily Max Temparature")
plot(df.ts[,'temp'], main = "Daily Temparature")
```
```{r}
checkresiduals(df.ts[,'temp'])
```

```{r}
tsdisplay(df.ts[,'avg_temp'])
```
```{r}
Acf(df.ts[,'avg_temp'])
Pacf(df.ts[,'avg_temp'])
```
## The ACF and PACF shows that the data is an auto regressive process. Before applying any transformation, check for the statistical tests confirming the stationarity
```{r}
kpss.test(df.ts[,'avg_temp'])
```
```{r}
adf.test(df.ts[,'avg_temp'])
```
The statistical tests say that the process is stationary. However, we will check for each factor individually.


## Apply boxcox transformation to see if there is any need for variance stabilization 
```{r}
BoxCox.lambda(df.ts[,'avg_temp'])
```
BoxCox transformation does show that the stabilization is needed

### Decompose the timeseries data by applying the recommended lambda value

```{r}
df.ts.boxcox <- BoxCox(df.ts[,'avg_temp'], lambda = 1.5)
plot(decompose(df.ts.boxcox, type = "additive"))
plot(decompose(df.ts.boxcox, type = "multiplicative"))
```
Considering the magnitude of the components, choosing additive time series is more sensible.

```{r}
Acf(df.ts.boxcox)
Pacf(df.ts.boxcox)
```

## Applying differencing to remove the seasonality
```{r}
diff1 <- diff(df.ts.boxcox, order = 1)
plot(diff1)
```
```{r}
Acf(diff1)
Pacf(diff1)
```


```{r}
adf.test(diff1)
```
It is stationary but looks more like white noise

```{r}
Acf(df.ts.boxcox)
Pacf(df.ts.boxcox)
```
### Split the train and test datasets
```{r}
# Split the train and test datasets
data.train <- window(df.ts, start = c(1970, 1), end = c(2020, 365.25))

yday_23 <- as.numeric(as.POSIXlt("2023-07-31")$yday)
data.test <- window(df.ts, start = c(2021, 0), end = c(2023, yday_23))
```

```{r}
tsdisplay(data.test[,'avg_temp'])
```


## Base model
### Seasonal Naive
```{r}
fit.snaive <- snaive(data.train[,'avg_temp'], level = c(80,95), lambda = 1.45, h = length(data.test[,'avg_temp']))
summary(fit.snaive)
```
```{r}
# Create a plot with forecasted and actual values
plot <- autoplot(fit.snaive) + autolayer(data.test[,'avg_temp'])

# Specify the x-axis limits for the last 4 years
last_year <- 2019
plot <- plot + scale_x_continuous(
  limits = c(last_year, 2024),
  breaks = seq(last_year, 2024, by = 1)
)

# Display the plot
print(plot)
```
```{r}
accuracy(fit.snaive, data.test[,"avg_temp"])
```


## Though the visual might show it is near to the actual values, the error metrics from the summary show there is a lot of improvement area. RMSE is ~6 and MAE is ~5.3 degrees C which is very high.

## Holt Winters might be suitable for the use case since it captures both the trend and seasonality in the data
```{r}
fit_hw.linear_add.damp <- hw(visitors_ts[,'Arrivals'],seasonal = 'additive', h = 20, damped = TRUE)
plot(fit_hw.linear_add.damp)
```


```{r}
fit.ses <- ses(data.train[,"avg_temp"], h = length(data.test[, "avg_temp"]), alpha = 0.2)
plot(fit.ses, ylab="Temperature(°C)",)
```

```{r}
hw_train = 
fit.hw_add <- hw(data.train[,"avg_temp"],　seasonal="additive", 
                 h = length(data.test[,'avg_temp']), frequency = 365, damped = TRUE, alpha = 0.2)
plot(fit.hw_add, ylab="Temperature(°C)")

```

```{r}
accuracy(fit_hw_add, df_mon_test_ts[,"avgMTemp"])
```
```{r}
summary(fit_hw_add)
```

```{r}
ls1 <- df_mon_test_ts[,"avgMTemp"]
ls2 <- fit_hw_add$mean
mse = mean((ls1-ls2)^2)
round(mse,2)
rmse = sqrt(mse)
round(rmse,2)
```


## As previously observed from the ACF and PACF plots, trying out a seasonal ARIMA might give better results

## Seasonal ARIMA using auto.arima

```{r}
model.sarima <- auto.arima(data.train[,'avg_temp'], lambda = 1.45, trace = TRUE, seasonal = TRUE)
```

```{r}
best.arima <- Arima(data.train[,'avg_temp'], order = c(3,0,0), 
                    seasonal = list(order=c(0,1,0), period = 365), lambda = 1.45)
summary(best.arima)
```

```{r}
source('eacf.R')
```

```{r}
eacf(data.train[,'avg_temp'])
```
```{r}
arima.eacf.202 <- Arima(data.train[,'avg_temp'], order = c(2,0,2), 
      seasonal = list(order = c(0,1,0), period = 365.25), lambda = 1.45)
summary(arima.eacf.202)
```















